{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Let us welcome SciPy!\n",
    "from scipy.stats import (trim_mean, mode, skew, \n",
    "gaussian_kde, pearsonr, spearmanr, beta)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "sns.set(rc={'figure.figsize': (16., 9.)})\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats.distributions as dist\n",
    "\n",
    "import matplotlib as mpl\n",
    "from dateutil.parser import parse\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855b02e",
   "metadata": {},
   "source": [
    "# Intro to probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3f38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define your sample space\n",
    "sample_space = [\"H\", \"T\"]\n",
    "\n",
    "# run experiment 1000 times \n",
    "flips = random.choices(sample_space, k=1000)\n",
    "\n",
    "# compute how many heads appeared\n",
    "frequency_H = flips.count(\"H\") / len(flips)\n",
    "frequency_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = [1, 2, 3, 4, 5, 6]\n",
    "# run experiment 10.000 times \n",
    "rolls = random.choices(sample_space, k=10_000)\n",
    "frequency_fours = rolls.count(4) / len(rolls)\n",
    "frequency_fours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c3e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(rolls)[4] / 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b04895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552c8826",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(flips)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77763c4a",
   "metadata": {},
   "source": [
    "## Rules\n",
    "\n",
    "Laplace: $$ P(\\text{event})=\\frac{\\text{favorable events}}{\\text{total events}} $$\n",
    "\n",
    "Union of events: $$ P(A \\cup B)=P(A)+P(B)-P(A \\cap B) $$\n",
    "\n",
    "Intersection of events: $$ P(A \\cap B)=P(A) \\cdot P(B|A) $$\n",
    "\n",
    "[Monty Hall problem](https://en.wikipedia.org/wiki/Monty_Hall_problem)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e00f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pA = 0.3\n",
    "pB = 0.5\n",
    "pAyB = pA * pB  # if they are independent\n",
    "\n",
    "pAUB = pA + pB - pAyB\n",
    "pAUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if they are not independet\n",
    "pBA = 0.4\n",
    "pA = 0.3\n",
    "\n",
    "pAyB = pA * pBA\n",
    "pAyB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc242c6c",
   "metadata": {},
   "source": [
    "## Questions\n",
    "* 3 coins are tossed: what is the probability of 3 heads in a row?\n",
    "* 3 coins are tossed: what is the probability of 2 heads in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc58d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "pH = 0.5\n",
    "prob_three_heads_in_a_row = pH * pH * pH\n",
    "prob_three_heads_in_a_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a64eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41f29f",
   "metadata": {},
   "source": [
    "$$ P(2 \\text{heads}) = \\frac{\\text{eventos favorables}}{\\text{eventos totales}} = \\frac{ 3\\choose 2 }{2^3} = \\frac{ \\frac{3!}{2!(3-2)!} }{ 2^3 } = \\frac{\\frac{3 \\cdot 2 \\cdot 1}{2 \\cdot 1 \\cdot (1)}}{8} = \\frac{\\frac{3}{1}}{8} = \\frac{3}{8} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 sobre 2 --> de tres eventos, que dos sean caras\n",
    "# 2 ** 3  --> ramifico 3 veces, y en cada ramificación salen 2 ramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25fc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: real value -> with the tree / diagram\n",
    "3 / 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1ed07",
   "metadata": {},
   "source": [
    "EJERCICIO: ¿Cuál es la probabilidad de dos caras seguidas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85135c4a",
   "metadata": {},
   "source": [
    "# Discrete probability distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63735a2e",
   "metadata": {},
   "source": [
    "## Bernoulli distribution\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n",
    "\n",
    "Keys: 2 possible outcomes $\\Omega=\\{0,1\\}$ with probability $1-p$ and $p$. Example: biased coin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effbc67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bernoulli\n",
    "\n",
    "my_bernoulli = bernoulli(p=0.8)\n",
    "\n",
    "sample = my_bernoulli.rvs(size=100)\n",
    "\n",
    "print(Counter(sample))\n",
    "\n",
    "sns.countplot(x=sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad1341c",
   "metadata": {},
   "source": [
    "## Binomial Distribution\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution)\n",
    "\n",
    "The Binomial distribution generalizes Bernouilli to the case were we do more than 1 \"trial\". \n",
    "It gives us the probability of having $k$ successes in $N$ total trials of Bernulli with probability $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb94db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "\n",
    "my_binomial = binom(n=100, p=0.8)\n",
    "\n",
    "sample = my_binomial.rvs(size=500)\n",
    "\n",
    "Counter(sample) \n",
    "\n",
    "sns.countplot(x=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaf0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial.pmf(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39888251",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial.cdf(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e209a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8a6551",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_binomial.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eac344",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=my_binomial.rvs(size=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee47c63",
   "metadata": {},
   "source": [
    "## Discrete probability distributions: Poisson\n",
    "\n",
    "The Poisson distribution is used to describe _how many times something might happen in a specific timeframe_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef2698",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import poisson\n",
    "\n",
    "my_poisson = poisson(mu=15)\n",
    "\n",
    "my_sampled_values = my_poisson.rvs(size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95c6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,30)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, poisson(mu=15).pmf(x), 'bo')\n",
    "ax.vlines(x, 0, poisson(mu=15).pmf(x), colors='b', lw=5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3712dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,30)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(x, my_poisson.cdf(x), 'bo')\n",
    "ax.vlines(x, 0, my_poisson.cdf(x), colors='b', lw=5, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece048f2",
   "metadata": {},
   "source": [
    "# Continuous distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d961ea",
   "metadata": {},
   "source": [
    "## Exponential distribution\n",
    "\n",
    "Models the time it takes for a random event (with a constant rate) to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc1f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "\n",
    "my_e = expon(scale=5)\n",
    "\n",
    "sample = my_e.rvs(size=1000)\n",
    "\n",
    "sns.histplot(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a630ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_expon = expon(scale=5)\n",
    "#my_expon = norm(0, 5)\n",
    "\n",
    "x = np.linspace(0, 20, 1000)\n",
    "\n",
    "y = my_expon.pdf(x)   # probabilty obtaining value X\n",
    "y2 = my_expon.cdf(x)  # probabilty obtaining a value =< X\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(x,y)\n",
    "ax2.plot(x,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b43aa",
   "metadata": {},
   "source": [
    "## Normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c143ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "my_normal = norm(loc=170, scale=10)\n",
    "\n",
    "x = np.linspace(120, 220, 100)\n",
    "y = my_normal.pdf(x)\n",
    "y2 = my_normal.cdf(x)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(x,y)\n",
    "ax2.plot(x,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75de684",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d7f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv = pd.read_csv('../Classroom-Materials/data/Advertising.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_adv);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd804ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a7fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9d490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = smf.ols('Sales ~ TV', data=df_adv).fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69988cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    y  =    m   *  x +    n\n",
    "# Sales = 0.0475 * TV + 7.0326"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5358baeb",
   "metadata": {},
   "source": [
    "# Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f874e5",
   "metadata": {},
   "source": [
    "In real life situations we only have access to samples of data, not to the entire population. Then, how can we draw conclussions about the underlying population as a whole? How confident can we be with this conclusions? The answer lies in the Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67e9419",
   "metadata": {},
   "source": [
    "## The Bootstrap\n",
    "\n",
    "In real life we can not recreate the sampling distribution... we can infer the values of some statistics with tricks as the ones described above and the CTL. But: can we do something more general for any statistic?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f4f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_distribution = np.random.beta(2,8,1000)\n",
    "\n",
    "plt.hist(skewed_distribution, bins=20, density=True)\n",
    "plt.axvline(np.mean(skewed_distribution),\n",
    "            c=\"red\",\n",
    "            linewidth= 3.,\n",
    "            linestyle='--',\n",
    "            label='mean') # plot the mean\n",
    "plt.title('Histogram of skewed distribution', size=20)\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da880a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of 50 values\n",
    "sample_size = 50\n",
    "sample = np.random.beta(2,8, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd19fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the CLT\n",
    "estimate_mean = np.mean(sample)\n",
    "estandard_error = np.std(sample)\n",
    "CI = estimate_mean - 1.96*estandard_error / np.sqrt(sample_size), estimate_mean + 1.96*estandard_error / np.sqrt(sample_size)\n",
    "print(f' Estimate of the mean: {np.round(estimate_mean, 2)}')\n",
    "print(f' 95% CI of the mean: {np.round(CI[0], 2), np.round(CI[1], 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3244ab",
   "metadata": {},
   "source": [
    "Using bootstrapping consits on recreating a fake sampling distribution by solely having one sample! Let's use this to calculate in a different way the above estimation for the mean and its CI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36438ba4",
   "metadata": {},
   "source": [
    "1) First, sample from the sample you already have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootsrapped_sample = np.random.choice(sample, sample_size)\n",
    "bootsrapped_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789435",
   "metadata": {},
   "source": [
    "2) Compute the mean of the bootstrapped sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bootsrapped_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d1b0e",
   "metadata": {},
   "source": [
    "3) Repeat that process many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe93588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrapped_sampling_distribution = [np.mean(np.random.choice(sample, sample_size)) \n",
    "                                      for _ in range(10000) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f886a5a",
   "metadata": {},
   "source": [
    "4) Compute the mean for all the repetitions you have made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e27e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(bootstrapped_sampling_distribution)\n",
    "CI = np.percentile(bootstrapped_sampling_distribution,[2.5,97.5])\n",
    "print(f' Bootstrapped estimate of the mean: {np.round(mean, 2)}')\n",
    "print(f' Bootstrapped 95% CI of the estimate: {np.round(CI[0], 3), np.round(CI[1], 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ae2d80",
   "metadata": {},
   "source": [
    "# Hypothesis testing\n",
    "\n",
    "The goal of classical hypothesis testing is to answer the question, “Given a sample and an apparent effect, what is the probability of seeing such an effect by chance?” Here’s how we answer that question:\n",
    "\n",
    "1. The first step is to quantify the size of the apparent effect by choosing a test statistic.\n",
    "\n",
    "2. The second step is to define a null hypothesis, which is a model of the system based on the assumption that the apparent effect is not real (i.e that it can be due to chance).\n",
    "\n",
    "3. The third step is to compute a p-value, which is the probability of seeing the apparent effect if the null hypothesis is true.\n",
    "\n",
    "4. The last step is to interpret the result. If the p-value is low, the effectis said to be statistically significant, which means that it is unlikely to have occurred by chance. In that case we infer that the effect is more likely to appear in the larger population.\n",
    "\n",
    "5. The logic of this process is similar to a proof by contradiction. To prove a mathematical statement, 𝐴, you assume temporarily that 𝐴 is false. If that assumption leads to a contradiction, you conclude that 𝐴 must actually be true. Similarly, to test a hypothesis like, “This effect is real,” we assume, temporarily, that it is not. That’s the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea70746",
   "metadata": {},
   "source": [
    "We have data for the number of heart diseases in the US population and know how frequent they are in Ireland (42%).\n",
    "\n",
    "The research question for this section is, “The population proportion of Ireland having heart disease is 42%. Are more people suffering from heart disease in the US”?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9319cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/heart.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976706ff",
   "metadata": {},
   "source": [
    "Now, find the answer to this research question step by step.\n",
    "\n",
    "Step 1: define the null hypothesis and alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e17bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ho: p0 = 0.42  # null hypothesis\n",
    "# Ha: p > 0.42   # alternative hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbca3c",
   "metadata": {},
   "source": [
    "Step 2: Assume that the dataset above is a representative sample from the population of the US. So, calculate the population proportion of the US having heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fab276",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_us = len(df[ df['target'] != 0 ]) / len(df)\n",
    "p_us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0946e9d6",
   "metadata": {},
   "source": [
    "The population proportion of the sample having heart disease is 0.46 or 46%. This percentage is more than the null hypothesis. That is 42%.\n",
    "\n",
    "But the question is if it is significantly more than 42%. If we take a different simple random sample, the currently observed population proportion (46%) can be different.\n",
    "\n",
    "To find out if the observed population proportion is significantly more than the null hypothesis, perform a hypothesis test.\n",
    "\n",
    "Step 3: Calculate the Test Statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c890457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard error \n",
    "se = np.sqrt(0.42 * (1-0.42) / len(df))\n",
    "se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best estimate\n",
    "be = p_us  # hypothesized estimate\n",
    "he = 0.42\n",
    "test_stat = (be - he)/se\n",
    "test_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d76b0",
   "metadata": {},
   "source": [
    "Step 4: Compute the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce28488",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = 2*dist.norm.cdf(-np.abs(test_stat))\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67306824",
   "metadata": {},
   "source": [
    "The p-value is 1.1189741027728995e-05. It means the sample population proportion (54% or 0.54) is 1.1189741027728995e-05 null standard errors above the null hypothesis.\n",
    "\n",
    "Step 5: Infer the conclusion from the p-value\n",
    "\n",
    "Consider the significance level alpha to be 5% or 0.05. A significance level of 5% or less means that there is a probability of 95% or greater that the results are not random.\n",
    "\n",
    "Here p-value is smaller than our considered significance level 0.05. So, we can reject the null hypothesis. That means there is  significant difference in population proportion having heart disease in Ireland and the US."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a49664",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdb6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from dateutil.parser import parse\n",
    "\n",
    "# import Australian drugs time series dataframe\n",
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', \n",
    "    parse_dates=['date'],\n",
    "    #index_col='date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2ad0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_df(df, x, y, title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
    "    plt.figure(figsize=(16,5), dpi=dpi)\n",
    "    plt.plot(x, y, color='tab:red')\n",
    "    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "    plt.show()\n",
    "\n",
    "plot_df(df, x=df.date, y=df.value, title='Monthly anti-diabetic drug sales in Australia from 1992 to 2008.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.date.dt.year\n",
    "df['month'] = [d.strftime('%b') for d in df.date]\n",
    "years = df['year'].unique()\n",
    "mycolors = np.random.choice(list(mpl.colors.XKCD_COLORS.keys()), len(years), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4716e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10), dpi= 80)\n",
    "\n",
    "for i, y in enumerate(years):\n",
    "    if i > 0:        \n",
    "        plt.plot('month', 'value', data=df[df.year==y], color=mycolors[i], label=y)\n",
    "        plt.text(\n",
    "            df[df.year==y].shape[0]-.9, \n",
    "            df[df.year==y].value[-1:].values[0], \n",
    "            y, \n",
    "            fontsize=12, \n",
    "            color=mycolors[i]\n",
    "        )\n",
    "\n",
    "plt.gca().set(xlim=(-0.3, 11), ylim=(2, 30), ylabel='$Drug Sales$', xlabel='$Month$')\n",
    "plt.yticks(fontsize=12, alpha=.7)\n",
    "plt.title(\"Seasonal Plot of Drug Sales Time Series\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad228bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df.value, x=df.year.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', \n",
    "    parse_dates=['date'], index_col=\"date\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bf335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(15,5))\n",
    "plt.plot(df.value)\n",
    "plt.plot(df.rolling(window=4).mean(), c=\"r\")\n",
    "plt.title(\"Monthly anti-diabetic drug sales in Australia\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb7316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/selva86/datasets/master/a10.csv', \n",
    "    parse_dates=['date'], index_col=\"date\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d849c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43018d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = seasonal_decompose(df.value, model=\"additive\")\n",
    "res.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b0b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = seasonal_decompose(df.value, model=\"multiplicative\")\n",
    "res.plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
